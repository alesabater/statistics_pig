/*
*
* Created on Jan 14, 2015
*
* @author: Alejandro Sabater
*/

/** 
 * Register dependencies - By using REGISTER you tell pig where to find the jars
 */
REGISTER 's3://mbeacon-hadoop-development/pig/statistics_2nd_sprint/jars/mongo-hadoop-pig-1.4.0-SNAPSHOT.jar'
REGISTER 's3://mbeacon-hadoop-development/pig/statistics_2nd_sprint/jars/mongo-hadoop-core-1.4.0-SNAPSHOT.jar'
REGISTER 's3://mbeacon-hadoop-development/pig/statistics_2nd_sprint/jars/mongo-2.10.1.jar'
REGISTER 's3://mbeacon-hadoop-development/pig/statistics_2nd_sprint/jars/StatsUtilsPig-1.0-SNAPSHOT.jar'

/** 
 * Alises - Set alias for UDF functions.
 * If the function receives some parameters you can specify them here in the ()
 */ 
DEFINE BSONLoader com.mongodb.hadoop.pig.BSONLoader();
DEFINE BSONStorage com.mongodb.hadoop.pig.BSONStorage();
DEFINE MongoStorage com.mongodb.hadoop.pig.MongoStorage();
DEFINE MongoLoader com.mongodb.hadoop.pig.MongoLoader();
DEFINE keysCombinations com.mobiquitynetworks.statsutilspig.keysCombinations();
DEFINE JsonStructure com.mobiquitynetworks.statsutilspig.JsonStructure();

/** 
 * Parameters - set default values here; you can override with -p on the command-line.
 * Or user -f to specify a file with the parameters's values.
 */
%DEFAULT EVENT_PATH 's3://mbeacon-hadoop-development/data/production/events.bson'
%DEFAULT REGION_VENUE_PATH 's3://mbeacon-hadoop-development/data/production/venues-region/part*.bson'
%DEFAULT COMBINATIONS_PATH 's3://mbeacon-hadoop-development/data/production/combinations/part-r-*'
%DEFAULT OUTPUT_PATH 's3://mbeacon-hadoop-development/statistics_interface/stat-hour.bson'
%DEFAULT DIMENSIONS_PATH 's3://mbeacon-hadoop-development/data/production/hadoop.bson'

/** 
 * Macros - Import any macro .pig file.
 */
IMPORT 's3://mbeacon-hadoop-development/pig/statistics_2nd_sprint/macros/stats_sprint2_macro.pig';


/**
 * Optimization - Set here parameters for optimization of performance
 * Description:
 *				
 *		
 */
--set mongo.job.input.format 'com.mongodb.hadoop.BSONFileInputFormat'
--set pig.cachedbag.memusage 0.7
--set pig.udf.profile true
--set pig.exec.mapPartAgg true
set mongo.job.output.format 'com.mongodb.hadoop.BSONFileOutputFormat'
set mapreduce.output.fileoutputformat.outputdir 's3://mbeacon-hadoop-development/data/production/statistics-production'

/**
 * Load - Events collection
 * Dependencies: mongo-hadoop-pig-1.4.0-SNAPSHOT.jar (mongo-driver)
 */
events = LOAD '$EVENT_PATH' 
		 USING BSONLoader();

/**
 * Load - Region-venues collection
 * Dependencies: mongo-hadoop-pig-1.4.0-SNAPSHOT.jar (mongo-driver)
 * This collection is the one generated by the venues_regions_relation_development.pig script
 */
venues = LOAD '$REGION_VENUE_PATH' 
		 USING BSONLoader();

/**
 * Load - Combinations collection
 * data generated by the dimensions_development.pig script
 */
combinations = LOAD '$COMBINATIONS_PATH' 
			   USING TextLoader() as combinations:chararray;

/**
 * Load - Dimensions collection
 * Dependencies: mongo-hadoop-pig-1.4.0-SNAPSHOT.jar (mongo-driver)
 */
dimensions = LOAD '$DIMENSIONS_PATH' USING BSONLoader();

/**
 * Filter - Dismiss ObjectIds 
 * input --> ([_id#5475bf25313569af760e4d41,dimension#{type=id, real=venue.id, name=Venue Id}])
 */
dimensions = FOREACH dimensions 
			 GENERATE $0#'dimension';

/**
 * Turning dataset into flat structure
 * input --> ([type#id,real#venue.id,name#Venue Id])
 */
dimensions = FOREACH (GROUP dimensions ALL) 
   			 GENERATE dimensions;

/**
 * Filter - Events that are of extType = ['BCN'] and action = ['ENT']
 *							or extType = ['NOT'] and action = ['CLK','DSP']
 * input --> ([app#be119bdc27c47750acce35c50ed9d09fbedfddd4,_id#54c3aecfed3bac36638b44e3,event#{timestamp=1422110414630, localtime=1422092414630,
 *			   extType=GFC, source=REST, tzOffset=300, action=EXT, value={geofence=null}, type=MOB},device#{type=iPhone5,3, os=iOS, idFA=1942F46D-2A52-427E-8981-2F49E4763AE8,
 *			   osVersion=8.0},sdk#{build=10, version=2.0.2},user#{role=public},clientId#53e2531b0af550b232aef6f5])
 * schema --> events: {document: map[]}
 */
events = FILTER events BY $0#'event'#'localtime' is not null and 
						  ($0#'event'#'extType'=='NOT' or $0#'event'#'extType'=='BCN') and 
						  ($0#'event'#'action'=='CLK' or $0#'event'#'action'=='DSP' or $0#'event'#'action'=='ENT');


/**
 * Rename - Establishing known names for the fields of the schema --> Easier to do stuff later
 * input --> ([app#be119bdc27c47750acce35c50ed9d09fbedfddd4,_id#54baa06e5cde257233749e4f,event#{timestamp=1421516874351, localtime=1421498874351,
 *			  extType=BCN, source=REST, tzOffset=300, action=ENT, value={beacon=539850be6375f9c787ff0750}, type=MOB},device#{type=iPhone5,2, os=iOS,
 *			  idFA=5FADB114-67C3-44AB-90B9-300890BE77DD, osVersion=7.1.2},sdk#{build=4, version=1.0.3},user#{role=public},clientId#53e2531b0af550b232aef6f5])
 * schema --> events: {document: map[]}
 */
events = FOREACH events GENERATE TOMAP(
									   'app',$0#'app',
									   'event.timestamp',(datetime)$0#'event'#'timestamp',
									   'event.localtime',(datetime)$0#'event'#'localtime',
									   'event.value.beacon',(chararray)$0#'event'#'value'#'beacon',
									   'event.value.notification',(chararray)$0#'event'#'value'#'notification',
									   'clientId',$0#'clientId',
									   'device.idDev',$0#'device'#'idDev',
									   'device.idFA',$0#'device'#'idFA',
									   'device.os',$0#'device'#'os',
									   'event.type',$0#'event'#'type',
									   'event.extType',$0#'event'#'extType',
									   'event.action',$0#'event'#'action');
/**
 *
 * Join - Events with venues using beaconIds as joining field
 * input --> ([device.idDev#,app#be119bdc27c47750acce35c50ed9d09fbedfddd4,event.value.beacon#5466129e65c0e8eccf9dd46f,event.value.notification#,
 *	          event.type#MOB,device.idFA#3A788744-9CF3-4525-8AF8-308382724278,event.localtime#2014-10-30T01:21:01.425+01:00,device.os#iOS,
 *	          event.extType#BCN,event.timestamp#2014-10-30T01:21:01.425+01:00,event.action#ENT,clientId#53e2531b0af550b232aef6f5])
 * schema --> events: {map[]}
 *
 * Note - If you would want to join the events data set with other collection e.g. campaings, you would need to load the campaing events, filter the data 
 * 		  you are interested in and then perdorm the join by the value.campaing field
 *
 *		  events-cmp = JOIN events
 *                     BY (chararray)$0#'event.value.campaing',
 * 					      venues
 *					   BY (chararray)$0#'beaconId';
 */
events = JOIN events 
		 BY (chararray)$0#'event.value.beacon',
			venues
		 BY (chararray)$0#'beaconId';

/**
 * UDF - UDF that creates all the possible combinations that an event can have based on the input features for statistics(hadoop collection)
 *		 It creates the same amount of events as possible combinations between the features for each event instance.
 * input --> ([device.idDev#,app#be119bdc27c47750acce35c50ed9d09fbedfddd4,event.value.notification#,event.value.beacon#5391df950af5509d247b23ca,event.type#MOB,
 * 			   device.idFA#6DB95209-AA03-4791-B287-28E1EDB92941,event.localtime#2014-10-22T17:43:04.796+02:00,device.os#iOS,event.extType#BCN,event.timestamp#2014-10-22T17:43:04.796+02:00,
 *			   event.action#ENT,clientId#53e2531b0af550b232aef6f5],[venue.country#us,venue.type#Other,beaconId#5391df950af5509d247b23ca,venue.id#54b041820af5506a0abbcdc8,
 *			   venue.name#Josh Glantz,venue.location.state#NY,venue.metrics.dma#]) 
 * schema --> events: {map[],venues::venue: map[]}
 *
 * UDF @params --> event info, venue info, combinations
 *
 * Note - The UDF returns a bag of events, because a UDF can only analyse 1 event at a time and can only return one value, that is why all the combinations of events are embedded
 *        into a bag and the flatten out, leaving us with the same amount of rows as the amount of elements the bag had, e.g. if the bag has 64 elements and we flatten it out, we
 *        will end up with 64 rows, each corresponding to a element of the previous bag
 *
 */
events = FOREACH events 
		 GENERATE FLATTEN(keysCombinations($0,$1,combinations.$0)),
		 		  $0#'event.action' as action:chararray;

/**
 * Macro - Macro that gets the year,month,day and hour from the event localtime and add them as fields to the event
 *
 * input --> (*|AZ||*|53b19a6b0af550e07817962f|*,2015-01-24T21:38:55.522+01:00,,4A6D1914-E480-42D4-875F-18C3DB529447,ENT)
 * schema --> events: {event_info::key: chararray,event_info::localtime: datetime,event_info::idFA: chararray,event_info::idDev: chararray,action: chararray}
 */
events = GENERATE_DATE_PARTS(events);

/**
 * Split - Splits the events into Beacon Enters and Notifications(clicked or displayed)
 * 
 * events_bcn_ent --> Beacon Enter
 * events_not --> Notifications
 *
 * input --> (5476d0d8a20d45dd20e8dd0e|PA|*|dbf158bc74de36e5a7ebec145d1524887fc9313b|53b19a6b0af550e07817962f|King of Prussia Mall,
 *			  2015-01-24T16:08:35.092+01:00,,B80655F7-11C4-46F1-B231-B8A7B1935860,ENT,2015,1,24,16)
 * schema --> events: {event_info::key: chararray,event_info::localtime: datetime,event_info::idFA: chararray,
 *			           event_info::idDev: chararray,action: chararray,year: int,month: int,day: int,hour: int}
 */
SPLIT events INTO events_bcn_ent IF action == 'ENT',
	  			  events_not IF (action == 'CLK' or action == 'DSP');

/**
 * Reshape - Rename events and add integer flag for the king of event
 *           Possible kind of events: Beacon enter, notification clicked, notification displayed
 *			 Values for integer flags: 1 if is that type of event, 0 if not
 * 
 * input --> (5476d0d8a20d45dd20e8dd0e|PA|*|dbf158bc74de36e5a7ebec145d1524887fc9313b|53b19a6b0af550e07817962f|King of Prussia Mall,
 *			  2015-01-24T16:08:35.092+01:00,,B80655F7-11C4-46F1-B231-B8A7B1935860,ENT,2015,1,24,16)
 * schema --> events: {event_info::key: chararray,event_info::localtime: datetime,event_info::idFA: chararray,
 *			           event_info::idDev: chararray,action: chararray,year: int,month: int,day: int,hour: int}
 */
events_not = FOREACH events_not
			 GENERATE key as key:chararray,
			 		  year,
			 		  month,
			 		  day,
			 		  hour,
			 		  (action == 'CLK'?1:0) as clk:int,
			 		  (action == 'DSP'?1:0) as dsp:int,
			 		  0 as ent:int;

/**
 * Reshape - Rename events, add integer flag for the king of event and group events by hour so we take the first occurrence of each day
 *           Possible kind of events: Beacon enter, notification clicked, notification displayed
 *			 Values for integer flags: 1 if is that type of event, 0 if not
 * 
 * input --> (5476d0d8a20d45dd20e8dd0e|PA|*|dbf158bc74de36e5a7ebec145d1524887fc9313b|53b19a6b0af550e07817962f|King of Prussia Mall,
 *			  2015-01-24T16:08:35.092+01:00,,B80655F7-11C4-46F1-B231-B8A7B1935860,ENT,2015,1,24,16)
 * schema --> events: {event_info::key: chararray,event_info::localtime: datetime,event_info::idFA: chararray,
 *			           event_info::idDev: chararray,action: chararray,year: int,month: int,day: int,hour: int}
 */
events_bcn_ent = FOREACH (GROUP events_bcn_ent BY (idFA,idDev,key,year,month,day)) 
				 GENERATE group.key as key:chararray,
				 		  group.year as year:int,
				 		  group.month as month:int,
				 		  group.day as day:int,
				 		  MIN(events_bcn_ent.hour) as hour:int,
				 		  0 as clk:int,
				 		  0 as dsp:int,
				 		  1 as ent:int;


/**
 * Union - Union of events_bcn_ent and events_not.
 *
 * Schema --> events: {key: chararray,year: int,month: int,day: int,hour: int,clk: int,dsp: int,ent: int}
 */
events = UNION events_not,
			   events_bcn_ent;			     


/**
 * Group & Count - Group and count of hourly instances
 *
 * input --> 
 * Schema --> 
 */
events_hour = GROUP events BY (key,year,month,day,hour);
events_hour_count = FOREACH events_hour GENERATE group, 
												 SUM(events.ent) as hour_count_ent:int, 
												 SUM(events.clk) as hour_count_clk:int, 
												 SUM(events.dsp) as hour_count_dsp:int;

/**
 * Group & Count - Group and count of daily instances
 *
 * input --> ((*|CA||*|53b19a6b0af550e07817962f|Santa Monica Place,2015,1,25,14),1,0,0)
 * Schema --> events_hour_count: {tup: (key: chararray,year: int,month: int,day: int,hour: int),hour_count_ent: int,hour_count_clk: int,hour_count_dsp: int}
 */
events_day = GROUP events_hour_count BY (group.key,group.year,group.month,group.day);
events_day_count = FOREACH events_day GENERATE group, 
											   SUM(events_hour_count.hour_count_ent) as day_count_ent:int, 
											   SUM(events_hour_count.hour_count_clk) as day_count_clk:int, 
											   SUM(events_hour_count.hour_count_dsp) as day_count_dsp:int;

/**
 * Group & Count - Group and count of monthly instances
 *
 * input --> ((*|CA||*|53b19a6b0af550e07817962f|Santa Monica Place,2015,1,25),11,3,2)
 * Schema --> events_day_count: {tup: (key: chararray,year: int,month: int,day: int),hour_count_ent: int,hour_count_clk: int,hour_count_dsp: int}
 */
events_month = GROUP events_day_count BY (group.key,group.year,group.month);
events_month_count = FOREACH events_month GENERATE group, 
												   SUM(events_day_count.day_count_ent) as month_count_ent:int, 
												   SUM(events_day_count.day_count_clk) as month_count_clk:int, 
												   SUM(events_day_count.day_count_dsp) as month_count_dsp:int;

/**
 * Group & Count - Group and count of yearly instances
 *
 * input --> ((*|CA||*|53b19a6b0af550e07817962f|Santa Monica Place,2015,1),35,5,8)
 * Schema --> events_month_count: {tup: (key: chararray,year: int,month: int),hour_count_ent: int,hour_count_clk: int,hour_count_dsp: int}
 */
events_year = GROUP events_month_count BY (group.key,group.year);
events_year_count = FOREACH events_year GENERATE group, 
												 SUM(events_month_count.month_count_ent) as year_count_ent:int, 
												 SUM(events_month_count.month_count_clk) as year_count_clk:int, 
												 SUM(events_month_count.month_count_dsp) as year_count_dsp:int;

/**
 * Union - Union of counts of eventes hourly, daily, monthly and yearly
 *
 * input --> events_hour_count: {tup: (key: chararray,year: int,month: int,day: int,hour: int),hour_count_ent: int,hour_count_clk: int,hour_count_dsp: int}
 *			 events_day_count: {tup: (key: chararray,year: int,month: int,day: int),hour_count_ent: int,hour_count_clk: int,hour_count_dsp: int}
 *			 events_month_count: {tup: (key: chararray,year: int,month: int),hour_count_ent: int,hour_count_clk: int,hour_count_dsp: int}
 *			 events_year_count: {tup: (key: chararray,year: int),hour_count_ent: int,hour_count_clk: int,hour_count_dsp: int}
 *
 * Schema --> events_month_count: {tup: (),hour_count_ent: int,hour_count_clk: int,hour_count_dsp: int}
 */
final_events = UNION events_hour_count, events_day_count, events_month_count, events_year_count;

/**
 * UDF - UDF that generates the needed structure to store the data into a .BSON file
 *
 * input --> ((*|CA||*|53b19a6b0af550e07817962f|Santa Monica Place,2015),200,35,21)
 *			 ((*|CA||*|53b19a6b0af550e07817962f|Santa Monica Place,2015,1),35,5,8)
 *			 ((*|CA||*|53b19a6b0af550e07817962f|Santa Monica Place,2015,1,23),9,2,4)
 *			 ((*|CA||*|53b19a6b0af550e07817962f|Santa Monica Place,2015,1,23,15),1,2,1)
 *
 * Schema --> events_month_count: {tup: (),hour_count_ent: int,hour_count_clk: int,hour_count_dsp: int}
 *
 * UDF @params --> dimensions(features), final events fields
 */
final_events = FOREACH final_events GENERATE JsonStructure(dimensions.$0, $0..);

/**
 * Store - Store data into the path set in line 54 with the following sentence: set mapreduce.output.fileoutputformat.outputdir 's3://mbeacon-hadoop-development/data/development/statistics-development'
 * 
 * Important Note: The $OUTPUT_PATH variable is just a symbolic variable due to impositions of pig syntax for store. It really does not matter where that variable points
 * it is never used, the path where the data will be stored is the one in line 54 
 */
STORE final_events INTO '$OUTPUT_PATH' USING BSONStorage();
